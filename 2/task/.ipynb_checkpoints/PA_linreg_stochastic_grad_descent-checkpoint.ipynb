{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('Advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  Radio  Newspaper  Sales\n",
       "0           1  230.1   37.8       69.2   22.1\n",
       "1           2   44.5   39.3       45.1   10.4\n",
       "2           3   17.2   45.9       69.3    9.3\n",
       "3           4  151.5   41.3       58.5   18.5\n",
       "4           5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = adver_data[['TV','Radio','Newspaper']].values# Ваш код здесь\n",
    "y = adver_data['Sales'].values# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 230.1,   37.8,   69.2],\n",
       "       [  44.5,   39.3,   45.1],\n",
       "       [  17.2,   45.9,   69.3],\n",
       "       [ 151.5,   41.3,   58.5],\n",
       "       [ 180.8,   10.8,   58.4]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "means, stds =np.mean(X,axis=0), np.std(X, axis=0) # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X+means # Ваш код здесь\n",
    "X = X/stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 147.0425,   23.264 ,   30.554 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "230.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.40384683,  4.12325868,  4.59185753],\n",
       "       [ 2.23661834,  4.22454402,  3.48249082],\n",
       "       [ 1.91783958,  4.67019952,  4.59646071],\n",
       "       [ 3.48604425,  4.35959115,  4.09931713],\n",
       "       [ 3.82817676,  2.30012256,  4.09471394],\n",
       "       [ 1.81858612,  4.8727702 ,  4.85884205],\n",
       "       [ 2.38841775,  3.78564088,  2.48820365],\n",
       "       [ 3.12055798,  2.89432989,  1.94042507],\n",
       "       [ 1.81741843,  1.71266758,  1.45248785],\n",
       "       [ 4.05003744,  1.74642936,  2.38233048],\n",
       "       [ 2.4888389 ,  1.96250476,  2.52042592],\n",
       "       [ 4.22402292,  3.19143355,  1.59058329],\n",
       "       [ 1.99490697,  3.94094507,  4.43995255],\n",
       "       [ 2.85549286,  2.08404716,  1.73788509],\n",
       "       [ 4.10024801,  3.79239324,  3.52391946],\n",
       "       [ 3.99865918,  4.79174193,  3.84153897],\n",
       "       [ 2.50868959,  4.04223041,  6.65408278],\n",
       "       [ 5.00287066,  4.24480109,  3.97503123],\n",
       "       [ 2.52503722,  2.95510109,  2.24883822],\n",
       "       [ 3.43700136,  3.1846812 ,  2.28566367],\n",
       "       [ 4.26722737,  3.44127073,  3.86455488],\n",
       "       [ 4.48908804,  1.91523826,  2.48820365],\n",
       "       [ 1.87113207,  2.64449271,  3.68963398],\n",
       "       [ 4.38282845,  2.71201627,  2.61248955],\n",
       "       [ 2.44446676,  2.42166497,  2.24883822],\n",
       "       [ 4.78684842,  1.80720057,  2.3040764 ],\n",
       "       [ 3.3856231 ,  3.54930842,  1.98645688],\n",
       "       [ 4.52061561,  2.69851156,  2.46058456],\n",
       "       [ 4.62220445,  3.40075659,  2.46058456],\n",
       "       [ 2.54138485,  2.65124507,  3.28455403],\n",
       "       [ 5.13715475,  3.48178486,  3.39503038],\n",
       "       [ 3.03531677,  2.74577805,  3.18328404],\n",
       "       [ 2.85198979,  1.67215345,  2.78741044],\n",
       "       [ 4.81837599,  2.92133931,  1.42026558],\n",
       "       [ 2.83447448,  1.66540109,  1.74709145],\n",
       "       [ 5.11146562,  1.8477147 ,  1.79772645],\n",
       "       [ 4.83355593,  4.52840005,  1.6366151 ],\n",
       "       [ 2.58926005,  4.90653198,  3.51010991],\n",
       "       [ 2.22027071,  3.37374717,  3.02217269],\n",
       "       [ 4.37932539,  4.11650633,  2.87947407],\n",
       "       [ 4.08156501,  3.0766435 ,  2.86106134],\n",
       "       [ 3.78380463,  3.82615502,  3.18788722],\n",
       "       [ 5.14532857,  3.44127073,  1.4893133 ],\n",
       "       [ 4.13294327,  2.13806601,  2.62169591],\n",
       "       [ 2.01008691,  3.30622361,  3.39963356],\n",
       "       [ 3.76161856,  3.09014821,  2.85645816],\n",
       "       [ 2.76441321,  2.23935135,  3.04979178],\n",
       "       [ 4.51828023,  4.37309586,  2.25804458],\n",
       "       [ 4.36998389,  2.63774036,  3.70344353],\n",
       "       [ 2.4981804 ,  2.36089376,  3.10042677],\n",
       "       [ 4.05003744,  1.78019114,  2.99915678],\n",
       "       [ 2.8893558 ,  2.21909428,  1.57217056],\n",
       "       [ 4.24387361,  4.38660057,  3.22931585],\n",
       "       [ 3.84919514,  4.69045659,  4.10852349],\n",
       "       [ 4.78451305,  3.51554664,  2.13836187],\n",
       "       [ 4.03952825,  4.90653198,  4.16836485],\n",
       "       [ 1.80223849,  3.46828015,  3.31217311],\n",
       "       [ 3.30738802,  2.86732046,  2.17058414],\n",
       "       [ 4.17848309,  4.9200367 ,  3.1418554 ],\n",
       "       [ 4.17731541,  3.56281313,  1.8345519 ],\n",
       "       [ 2.34171024,  1.70591523,  2.39153684],\n",
       "       [ 4.76816542,  4.45412413,  3.92439623],\n",
       "       [ 4.51127411,  2.61748329,  2.66312454],\n",
       "       [ 2.91621262,  3.56956549,  1.79312327],\n",
       "       [ 3.24783595,  4.46087649,  2.73677544],\n",
       "       [ 2.52270184,  2.19883722,  1.44788466],\n",
       "       [ 2.08481893,  3.23194769,  1.50772602],\n",
       "       [ 3.34358634,  2.54995973,  1.87598053],\n",
       "       [ 4.48908804,  3.42776601,  1.91280598],\n",
       "       [ 4.24854436,  4.5351524 ,  2.65852136],\n",
       "       [ 4.04186363,  3.63708905,  3.18788722],\n",
       "       [ 2.99911845,  2.53645502,  2.86566452],\n",
       "       [ 2.0299376 ,  3.7991456 ,  2.29487003],\n",
       "       [ 3.22798525,  1.9557524 ,  2.8472518 ],\n",
       "       [ 4.20884298,  3.23194769,  2.00947279],\n",
       "       [ 1.91433652,  4.52164769,  5.52170016],\n",
       "       [ 2.03811142,  1.6789058 ,  2.35931457],\n",
       "       [ 3.12406104,  3.49528957,  2.06010778],\n",
       "       [ 1.78005242,  3.58982256,  1.83915508],\n",
       "       [ 3.07151509,  2.09079952,  2.46979093],\n",
       "       [ 2.60911074,  3.37374717,  2.43296547],\n",
       "       [ 4.51711255,  1.8477147 ,  3.10502995],\n",
       "       [ 2.59626617,  2.94159638,  2.90248997],\n",
       "       [ 2.51569572,  4.57566654,  3.04518859],\n",
       "       [ 4.21001066,  4.4743812 ,  2.96233133],\n",
       "       [ 3.97297005,  2.81330162,  4.43074618],\n",
       "       [ 2.60794305,  3.42776601,  2.14296505],\n",
       "       [ 3.00962764,  4.31232465,  4.31566665],\n",
       "       [ 2.74806558,  3.29271889,  4.78519115],\n",
       "       [ 2.99911845,  4.79849429,  3.77249125],\n",
       "       [ 3.28520195,  1.90173355,  1.8345519 ],\n",
       "       [ 2.05095598,  1.67215345,  2.92550588],\n",
       "       [ 4.25905355,  3.83290738,  4.12233303],\n",
       "       [ 4.64672589,  4.03547806,  4.73455615],\n",
       "       [ 2.97109394,  2.51619795,  1.9082028 ],\n",
       "       [ 3.62383141,  3.70461261,  3.84153897],\n",
       "       [ 4.02434831,  1.80720057,  1.67804373],\n",
       "       [ 3.87605196,  2.98886287,  2.41915593],\n",
       "       [ 5.09978874,  4.42711471,  3.76328489],\n",
       "       [ 3.29571114,  4.38660057,  3.51931627],\n",
       "       [ 4.31393488,  1.86121942,  3.69884035],\n",
       "       [ 5.17802382,  4.02197334,  6.05106602],\n",
       "       [ 4.9888584 ,  2.25285606,  2.39153684],\n",
       "       [ 3.9110826 ,  2.73227334,  2.23042549],\n",
       "       [ 4.49842954,  3.88692622,  1.65042464],\n",
       "       [ 3.32723871,  4.7039613 ,  4.12233303],\n",
       "       [ 2.00891923,  2.31362727,  2.77360089],\n",
       "       [ 2.77258702,  1.59112517,  2.47439411],\n",
       "       [ 1.86996438,  1.59787753,  2.58487046],\n",
       "       [ 4.69927184,  3.38725188,  1.65963101],\n",
       "       [ 4.35363626,  2.1245613 ,  4.0072535 ],\n",
       "       [ 4.53929861,  4.1367634 ,  2.47439411],\n",
       "       [ 3.76862469,  2.61073093,  1.51693238],\n",
       "       [ 4.16447084,  2.96185345,  1.89899644],\n",
       "       [ 2.63012912,  4.73097073,  2.9945536 ],\n",
       "       [ 2.5939308 ,  3.93419272,  3.83233261],\n",
       "       [ 3.34241865,  2.53645502,  2.58487046],\n",
       "       [ 2.60911074,  1.62488695,  2.08772687],\n",
       "       [ 3.18478081,  4.06248748,  5.05217567],\n",
       "       [ 1.94352871,  2.65124507,  2.43296547],\n",
       "       [ 3.3669401 ,  3.38049952,  3.53312582],\n",
       "       [ 1.93652258,  3.03612936,  3.72645944],\n",
       "       [ 4.33261788,  1.73292465,  2.12455232],\n",
       "       [ 3.15442092,  3.90718329,  1.97725052],\n",
       "       [ 4.39684071,  3.7518791 ,  4.8220166 ],\n",
       "       [ 2.73522102,  2.36764612,  2.59868   ],\n",
       "       [ 1.80807693,  4.1975346 ,  3.7356658 ],\n",
       "       [ 2.65348287,  1.57086811,  1.82994872],\n",
       "       [ 4.28941343,  4.87952256,  1.55375784],\n",
       "       [ 2.41293919,  2.38115083,  3.3904272 ],\n",
       "       [ 1.7251711 ,  4.24480109,  1.80693281],\n",
       "       [ 4.81370524,  1.76668643,  3.38582402],\n",
       "       [ 1.81508306,  3.40750895,  1.50312284],\n",
       "       [ 4.28357499,  3.83290738,  3.48249082],\n",
       "       [ 2.14787407,  4.17727753,  4.426143  ],\n",
       "       [ 2.28099047,  4.74447544,  1.79772645],\n",
       "       [ 2.01592535,  4.20428696,  1.8345519 ],\n",
       "       [ 4.9129587 ,  3.522299  ,  4.1545553 ],\n",
       "       [ 2.21910302,  3.31972832,  2.35010821],\n",
       "       [ 3.87605196,  4.5351524 ,  1.48471011],\n",
       "       [ 2.5740801 ,  2.71876863,  2.00026643],\n",
       "       [ 3.97880849,  3.96120214,  4.88646114],\n",
       "       [ 4.29174881,  3.81265031,  3.15106177],\n",
       "       [ 2.93839869,  1.9557524 ,  2.98995042],\n",
       "       [ 2.84031291,  2.5702168 ,  3.19709358],\n",
       "       [ 3.35526322,  1.69916287,  1.82074235],\n",
       "       [ 4.52061561,  2.0637901 ,  1.80693281],\n",
       "       [ 4.55681393,  4.87952256,  3.44566537],\n",
       "       [ 2.16071863,  4.29206759,  1.95423461],\n",
       "       [ 2.23895372,  3.31297596,  2.35471139],\n",
       "       [ 4.99469684,  2.50944559,  3.10963313],\n",
       "       [ 3.12989948,  2.13806601,  3.64820535],\n",
       "       [ 4.02434831,  3.14416706,  2.06010778],\n",
       "       [ 3.71724643,  4.25155345,  3.1418554 ],\n",
       "       [ 3.90991491,  2.99561523,  1.84375826],\n",
       "       [ 1.76487248,  2.35414141,  1.66883737],\n",
       "       [ 2.8134561 ,  4.50814298,  3.73106262],\n",
       "       [ 3.46619356,  1.65864873,  2.5250291 ],\n",
       "       [ 1.85361675,  4.06248748,  3.48709401],\n",
       "       [ 3.25484207,  2.81330162,  2.99915678],\n",
       "       [ 3.73125868,  2.79304455,  2.81963271],\n",
       "       [ 2.7177057 ,  3.98821156,  3.67582444],\n",
       "       [ 3.91692104,  2.79304455,  2.58487046],\n",
       "       [ 3.62616678,  4.05573512,  1.74709145],\n",
       "       [ 3.08552735,  2.56346444,  1.65502783],\n",
       "       [ 4.4552251 ,  1.80044821,  5.30995382],\n",
       "       [ 1.92601339,  4.10975397,  2.4007432 ],\n",
       "       [ 4.13177558,  1.92199062,  2.29947322],\n",
       "       [ 4.23219673,  3.16442413,  4.05788849],\n",
       "       [ 5.0367336 ,  2.28661785,  1.70105964],\n",
       "       [ 2.30084117,  2.35414141,  2.2534414 ],\n",
       "       [ 3.63784366,  2.98211052,  3.58836399],\n",
       "       [ 1.94586409,  2.92809167,  2.18899686],\n",
       "       [ 3.68338348,  2.05028538,  1.99566325],\n",
       "       [ 4.31393488,  1.80044821,  2.00947279],\n",
       "       [ 4.95032471,  4.8727702 ,  3.33058584],\n",
       "       [ 4.61753369,  3.61007963,  2.34090185],\n",
       "       [ 3.70440186,  2.09755188,  3.02677587],\n",
       "       [ 4.94798933,  1.72617229,  2.49741001],\n",
       "       [ 3.65068822,  2.24610371,  2.21661595],\n",
       "       [ 3.54559633,  1.74642936,  1.78852008],\n",
       "       [ 4.26839505,  1.93549533,  2.66772772],\n",
       "       [ 2.37323781,  1.9557524 ,  2.77360089],\n",
       "       [ 5.0752673 ,  4.4743812 ,  4.71154025],\n",
       "       [ 4.68058883,  3.00911994,  2.78741044],\n",
       "       [ 4.1107572 ,  4.61618067,  2.30867958],\n",
       "       [ 3.34592172,  1.71266758,  2.63090227],\n",
       "       [ 3.9484486 ,  3.50879429,  2.24423504],\n",
       "       [ 5.0565843 ,  2.50944559,  1.57677374],\n",
       "       [ 1.9353549 ,  2.38790319,  2.48360047],\n",
       "       [ 2.17823395,  4.34608643,  1.67344055],\n",
       "       [ 2.59860155,  2.30012256,  1.68264691],\n",
       "       [ 1.91783958,  1.8477147 ,  2.86106134],\n",
       "       [ 3.66470048,  4.40685764,  1.57217056],\n",
       "       [ 3.46502587,  3.97470685,  1.68264691],\n",
       "       [ 2.16305401,  1.82070528,  2.04169506],\n",
       "       [ 2.81695916,  1.90173355,  1.77931372],\n",
       "       [ 3.78380463,  2.19883722,  1.70105964],\n",
       "       [ 5.02855979,  4.40685764,  4.45376209],\n",
       "       [ 4.42720059,  2.15157072,  1.80693281]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.hstack # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer1 = # Ваш код здесь\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.linalg.inv  # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer2 = # Ваш код здесь\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer3 = # Ваш код здесь\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    grad0 = # Ваш код здесь\n",
    "    grad1 = # Ваш код здесь\n",
    "    grad2 = # Ваш код здесь\n",
    "    grad3 = # Ваш код здесь\n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - минимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        # Ваш код здесь\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer4 = # Ваш код здесь\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
